52/52 [==============================] - 0s 3ms/step - loss: 0.5427 - accuracy: 0.8252 - val_loss: 0.4728 - val_accuracy: 0.8551
Epoch 5/15
52/52 [==============================] - 0s 4ms/step - loss: 0.3988 - accuracy: 0.8898 - val_loss: 0.3462 - val_accuracy: 0.9205
Epoch 6/15
52/52 [==============================] - 0s 4ms/step - loss: 0.2757 - accuracy: 0.9507 - val_loss: 0.2081 - val_accuracy: 0.9716
Epoch 7/15
52/52 [==============================] - 0s 3ms/step - loss: 0.1519 - accuracy: 0.9793 - val_loss: 0.1388 - val_accuracy: 0.9688
Epoch 8/15
52/52 [==============================] - 0s 4ms/step - loss: 0.0850 - accuracy: 0.9866 - val_loss: 0.0934 - val_accuracy: 0.9773
Epoch 9/15
52/52 [==============================] - 0s 4ms/step - loss: 0.0653 - accuracy: 0.9890 - val_loss: 0.0922 - val_accuracy: 0.9830
Epoch 10/15
52/52 [==============================] - 0s 3ms/step - loss: 0.0539 - accuracy: 0.9903 - val_loss: 0.0792 - val_accuracy: 0.9801
Epoch 11/15
52/52 [==============================] - 0s 4ms/step - loss: 0.0441 - accuracy: 0.9915 - val_loss: 0.0723 - val_accuracy: 0.9830
Epoch 12/15
52/52 [==============================] - 0s 3ms/step - loss: 0.0400 - accuracy: 0.9933 - val_loss: 0.0849 - val_accuracy: 0.9773
Epoch 13/15
52/52 [==============================] - 0s 3ms/step - loss: 0.0420 - accuracy: 0.9890 - val_loss: 0.0743 - val_accuracy: 0.9773
Epoch 14/15
52/52 [==============================] - 0s 3ms/step - loss: 0.0372 - accuracy: 0.9903 - val_loss: 0.1015 - val_accuracy: 0.9716

Training Naive Bayes for bert_withoutIDF
Transforming X to non-negative values for Naive Bayes.
Naive Bayes Average Accuracy: 0.8453

Training Logistic Regression for bert_withoutIDF
Logistic Regression Average Accuracy: 0.9791

Training SVM for bert_withoutIDF
SVM Average Accuracy: 0.9774

Training Random Forest for bert_withoutIDF
Random Forest Average Accuracy: 0.9595
Results for bert_withoutIDF: {'Naive Bayes': 0.8452736861247498, 'Logistic Regression': 0.9791162029459901, 'SVM': 0.9774122567739589, 'Random Forest': 0.9595035460992907}

Processing file: sbert_vectors
Data loaded from C:/Users/danie/Desktop/IR/Information_retrieval/exe2/IR-files/bert-sbert/sbert_vectors.csv
Shape of X: (2346, 384), Shape of y: 2346
Unique labels in y: ['A-J' 'BBC' 'J-P' 'NY-T']

Training ANN Topology 1...
Epoch 1/15
52/52 [==============================] - 2s 8ms/step - loss: 1.3336 - accuracy: 0.3015 - val_loss: 1.2549 - val_accuracy: 0.3466
Epoch 2/15
52/52 [==============================] - 0s 3ms/step - loss: 1.1921 - accuracy: 0.4610 - val_loss: 1.1082 - val_accuracy: 0.5426
Epoch 3/15
52/52 [==============================] - 0s 3ms/step - loss: 1.0803 - accuracy: 0.5798 - val_loss: 1.0099 - val_accuracy: 0.6733
Epoch 4/15
52/52 [==============================] - 0s 5ms/step - loss: 0.9957 - accuracy: 0.6535 - val_loss: 0.9365 - val_accuracy: 0.6847
Epoch 5/15
52/52 [==============================] - 0s 4ms/step - loss: 0.9299 - accuracy: 0.6547 - val_loss: 0.8844 - val_accuracy: 0.6960
Epoch 6/15
52/52 [==============================] - 0s 4ms/step - loss: 0.8820 - accuracy: 0.6937 - val_loss: 0.8465 - val_accuracy: 0.7102
Epoch 7/15
52/52 [==============================] - 0s 4ms/step - loss: 0.8493 - accuracy: 0.7071 - val_loss: 0.8234 - val_accuracy: 0.7074
Epoch 8/15
52/52 [==============================] - 0s 4ms/step - loss: 0.8231 - accuracy: 0.7089 - val_loss: 0.8026 - val_accuracy: 0.7102
Epoch 9/15
52/52 [==============================] - 0s 4ms/step - loss: 0.8013 - accuracy: 0.7186 - val_loss: 0.7862 - val_accuracy: 0.7216
Epoch 10/15
52/52 [==============================] - 0s 4ms/step - loss: 0.7827 - accuracy: 0.7259 - val_loss: 0.7758 - val_accuracy: 0.7273
Epoch 11/15
52/52 [==============================] - 0s 4ms/step - loss: 0.7673 - accuracy: 0.7266 - val_loss: 0.7620 - val_accuracy: 0.7188
Epoch 12/15
52/52 [==============================] - 0s 4ms/step - loss: 0.7510 - accuracy: 0.7296 - val_loss: 0.7514 - val_accuracy: 0.7159
Epoch 13/15
52/52 [==============================] - 0s 4ms/step - loss: 0.7372 - accuracy: 0.7339 - val_loss: 0.7421 - val_accuracy: 0.7188
Epoch 14/15
52/52 [==============================] - 0s 4ms/step - loss: 0.7242 - accuracy: 0.7381 - val_loss: 0.7389 - val_accuracy: 0.7330
Epoch 15/15
52/52 [==============================] - 0s 4ms/step - loss: 0.7126 - accuracy: 0.7400 - val_loss: 0.7310 - val_accuracy: 0.7301

Training ANN Topology 2...
Epoch 1/15
52/52 [==============================] - 2s 9ms/step - loss: 1.3812 - accuracy: 0.3739 - val_loss: 1.3696 - val_accuracy: 0.3636
Epoch 2/15
52/52 [==============================] - 0s 3ms/step - loss: 1.3391 - accuracy: 0.2814 - val_loss: 1.2692 - val_accuracy: 0.2926
Epoch 3/15
52/52 [==============================] - 0s 5ms/step - loss: 1.1938 - accuracy: 0.3563 - val_loss: 1.0943 - val_accuracy: 0.5483
Epoch 4/15
52/52 [==============================] - 0s 4ms/step - loss: 1.0567 - accuracy: 0.5999 - val_loss: 0.9622 - val_accuracy: 0.6506
Epoch 5/15
52/52 [==============================] - 0s 4ms/step - loss: 0.9355 - accuracy: 0.6242 - val_loss: 0.8566 - val_accuracy: 0.6477
Epoch 6/15
52/52 [==============================] - 0s 4ms/step - loss: 0.8513 - accuracy: 0.6261 - val_loss: 0.7941 - val_accuracy: 0.6392
Epoch 7/15
52/52 [==============================] - 0s 4ms/step - loss: 0.7926 - accuracy: 0.6334 - val_loss: 0.7526 - val_accuracy: 0.6477
Epoch 8/15
52/52 [==============================] - 0s 4ms/step - loss: 0.7523 - accuracy: 0.6364 - val_loss: 0.7273 - val_accuracy: 0.6449
Epoch 9/15
52/52 [==============================] - 0s 3ms/step - loss: 0.7234 - accuracy: 0.6474 - val_loss: 0.7073 - val_accuracy: 0.6733
Epoch 10/15
52/52 [==============================] - 0s 3ms/step - loss: 0.6993 - accuracy: 0.7180 - val_loss: 0.6947 - val_accuracy: 0.7188
Epoch 11/15
52/52 [==============================] - 0s 4ms/step - loss: 0.6825 - accuracy: 0.7205 - val_loss: 0.6889 - val_accuracy: 0.7102
Epoch 12/15
52/52 [==============================] - 0s 4ms/step - loss: 0.6674 - accuracy: 0.7296 - val_loss: 0.6837 - val_accuracy: 0.7102
Epoch 13/15
52/52 [==============================] - 0s 4ms/step - loss: 0.6545 - accuracy: 0.7253 - val_loss: 0.6784 - val_accuracy: 0.7159
Epoch 14/15
52/52 [==============================] - 0s 3ms/step - loss: 0.6445 - accuracy: 0.7339 - val_loss: 0.6819 - val_accuracy: 0.7102
Epoch 15/15
52/52 [==============================] - 0s 4ms/step - loss: 0.6333 - accuracy: 0.7302 - val_loss: 0.6692 - val_accuracy: 0.7131

Training Naive Bayes for sbert_vectors
Transforming X to non-negative values for Naive Bayes.
Naive Bayes Average Accuracy: 0.6078

52/52 [==============================] - 0s 4ms/step - loss: 0.6333 - accuracy: 0.7302 - val_loss: 0.6692 - val_accuracy: 0.7131

Training Naive Bayes for sbert_vectors
Transforming X to non-negative values for Naive Bayes.
Naive Bayes Average Accuracy: 0.6078

acy: 0.7131

Training Naive Bayes for sbert_vectors
Transforming X to non-negative values for Naive Bayes.
Naive Bayes Average Accuracy: 0.6078


Training Naive Bayes for sbert_vectors
Transforming X to non-negative values for Naive Bayes.
Naive Bayes Average Accuracy: 0.6078

Transforming X to non-negative values for Naive Bayes.
Naive Bayes Average Accuracy: 0.6078

Training Logistic Regression for sbert_vectors
Logistic Regression Average Accuracy: 0.7118
Naive Bayes Average Accuracy: 0.6078

Training Logistic Regression for sbert_vectors
Logistic Regression Average Accuracy: 0.7118

Training SVM for sbert_vectors
SVM Average Accuracy: 0.6270
Training Logistic Regression for sbert_vectors
Logistic Regression Average Accuracy: 0.7118

Training SVM for sbert_vectors
SVM Average Accuracy: 0.6270

Training Random Forest for sbert_vectors

Training SVM for sbert_vectors
SVM Average Accuracy: 0.6270

Training Random Forest for sbert_vectors
Random Forest Average Accuracy: 0.8824
Training SVM for sbert_vectors
SVM Average Accuracy: 0.6270

Training Random Forest for sbert_vectors
Random Forest Average Accuracy: 0.8824

Training Random Forest for sbert_vectors
Random Forest Average Accuracy: 0.8824
Random Forest Average Accuracy: 0.8824
Results for sbert_vectors: {'Naive Bayes': 0.6078414257137661, 'Logistic Regression': 0.7118385160938352, 'SVM': 0.6270230951082014, 'Random Forest': 0.8823658847063103}
All tasks completed successfully!

C:\Users\danie\Desktop\IR\Information_retrieval\exe2>

C:\Users\danie\Desktop\IR\Information_retrieval\exe2>
C:\Users\danie\Desktop\IR\Information_retrieval\exe2> c: && cd c:\Users\danie\Desktop\IR\Information_retrieval\exe2 && cmd /C "c:\Users\danie\AppData\Local\Programs\Python\Python311\python.exe c:\Users\danie\.vscode\extensions\ms-python.debugpy-2024.14.0-win32-x64\bundled\libs\debugpy\adapter/../..\debugpy\launcher 62881 -- C:\Users\danie\Desktop\IR\Information_retrieval\exe2\bert_sbert_classification.py "

Processing file: bert_withIDF
Data loaded from C:/Users/danie/Desktop/IR/Information_retrieval/exe2/IR-files/bert-sbert/bert_withIDF.csv
Shape of X: (2346, 768), Shape of y: 2346     
Unique labels in y: ['A-J' 'BBC' 'J-P' 'NY-T']

Training ANN Topology 1...
Epoch 1/15
52/52 [==============================] - 1s 8ms/step - loss: 1.2634 - accuracy: 0.3508 - val_loss: 1.1790 - val_accuracy: 0.3864
Epoch 2/15
52/52 [==============================] - 0s 3ms/step - loss: 1.0407 - accuracy: 0.4519 - val_loss: 0.9077 - val_accuracy: 0.4886
Epoch 3/15
52/52 [==============================] - 0s 4ms/step - loss: 0.8760 - accuracy: 0.6315 - val_loss: 0.7829 - val_accuracy: 0.6790
Epoch 4/15
52/52 [==============================] - 0s 4ms/step - loss: 0.6593 - accuracy: 0.6912 - val_loss: 0.5263 - val_accuracy: 0.7216
Epoch 5/15
52/52 [==============================] - 0s 4ms/step - loss: 0.4609 - accuracy: 0.7771 - val_loss: 0.4270 - val_accuracy: 0.8523
Epoch 6/15
52/52 [==============================] - 0s 4ms/step - loss: 0.3615 - accuracy: 0.8770 - val_loss: 0.3335 - val_accuracy: 0.9432
Epoch 7/15
52/52 [==============================] - 0s 4ms/step - loss: 0.2480 - accuracy: 0.9574 - val_loss: 0.2253 - val_accuracy: 0.9688
Epoch 8/15
52/52 [==============================] - 0s 4ms/step - loss: 0.1625 - accuracy: 0.9708 - val_loss: 0.1697 - val_accuracy: 0.9574
Epoch 9/15
52/52 [==============================] - 0s 4ms/step - loss: 0.1108 - accuracy: 0.9793 - val_loss: 0.1416 - val_accuracy: 0.9574
Epoch 10/15
52/52 [==============================] - 0s 4ms/step - loss: 0.0834 - accuracy: 0.9848 - val_loss: 0.1383 - val_accuracy: 0.9631
Epoch 11/15
52/52 [==============================] - 0s 4ms/step - loss: 0.0699 - accuracy: 0.9884 - val_loss: 0.1245 - val_accuracy: 0.9659
Epoch 12/15
52/52 [==============================] - 0s 4ms/step - loss: 0.0627 - accuracy: 0.9903 - val_loss: 0.1240 - val_accuracy: 0.9716
Epoch 13/15
52/52 [==============================] - 0s 4ms/step - loss: 0.0522 - accuracy: 0.9921 - val_loss: 0.1144 - val_accuracy: 0.9716
Epoch 14/15
52/52 [==============================] - 0s 4ms/step - loss: 0.0485 - accuracy: 0.9927 - val_loss: 0.1132 - val_accuracy: 0.9744
Epoch 15/15
52/52 [==============================] - 0s 4ms/step - loss: 0.0466 - accuracy: 0.9909 - val_loss: 0.1123 - val_accuracy: 0.9744

Training ANN Topology 2...
Epoch 1/15
52/52 [==============================] - 2s 7ms/step - loss: 1.0034 - accuracy: 0.5250 - val_loss: 0.7058 - val_accuracy: 0.6278
Epoch 2/15
52/52 [==============================] - 0s 3ms/step - loss: 0.6429 - accuracy: 0.7357 - val_loss: 0.5440 - val_accuracy: 0.8608
Epoch 3/15
52/52 [==============================] - 0s 3ms/step - loss: 0.4570 - accuracy: 0.8733 - val_loss: 0.3493 - val_accuracy: 0.9091
Epoch 4/15
52/52 [==============================] - 0s 3ms/step - loss: 0.3060 - accuracy: 0.9074 - val_loss: 0.2459 - val_accuracy: 0.9318
Epoch 5/15
52/52 [==============================] - 0s 4ms/step - loss: 0.2151 - accuracy: 0.9440 - val_loss: 0.2049 - val_accuracy: 0.9403
Epoch 6/15
52/52 [==============================] - 0s 4ms/step - loss: 0.1679 - accuracy: 0.9641 - val_loss: 0.1830 - val_accuracy: 0.9716
Epoch 7/15
52/52 [==============================] - 0s 4ms/step - loss: 0.1362 - accuracy: 0.9677 - val_loss: 0.1426 - val_accuracy: 0.9631
Epoch 8/15
52/52 [==============================] - 0s 3ms/step - loss: 0.1291 - accuracy: 0.9720 - val_loss: 0.1572 - val_accuracy: 0.9517
Epoch 9/15
52/52 [==============================] - 0s 3ms/step - loss: 0.1022 - accuracy: 0.9781 - val_loss: 0.1316 - val_accuracy: 0.9688
Epoch 10/15
52/52 [==============================] - 0s 4ms/step - loss: 0.0820 - accuracy: 0.9805 - val_loss: 0.1167 - val_accuracy: 0.9716
Epoch 11/15
52/52 [==============================] - 0s 3ms/step - loss: 0.0775 - accuracy: 0.9787 - val_loss: 0.1113 - val_accuracy: 0.9744
Epoch 12/15
52/52 [==============================] - 0s 3ms/step - loss: 0.0696 - accuracy: 0.9836 - val_loss: 0.1167 - val_accuracy: 0.9744
Epoch 13/15
52/52 [==============================] - 0s 3ms/step - loss: 0.0597 - accuracy: 0.9896 - val_loss: 0.1073 - val_accuracy: 0.9716
Epoch 14/15
52/52 [==============================] - 0s 4ms/step - loss: 0.0533 - accuracy: 0.9909 - val_loss: 0.1193 - val_accuracy: 0.9659
Epoch 15/15
52/52 [==============================] - 0s 4ms/step - loss: 0.0476 - accuracy: 0.9890 - val_loss: 0.1033 - val_accuracy: 0.9858

Training Naive Bayes for bert_withIDF
Transforming X to non-negative values for Naive Bayes.
Naive Bayes Average Accuracy: 0.8551

Training Logistic Regression for bert_withIDF
Logistic Regression Average Accuracy: 0.9736

Training SVM for bert_withIDF
SVM Average Accuracy: 0.9736

Training Random Forest for bert_withIDF
Random Forest Average Accuracy: 0.9527
Results for bert_withIDF: {'Naive Bayes': 0.8550772867794144, 'Logistic Regression': 0.9735715584651754, 'SVM': 0.973577014002546, 'Random Forest': 0.9527004909983633}

Processing file: bert_withoutIDF
Data loaded from C:/Users/danie/Desktop/IR/Information_retrieval/exe2/IR-files/bert-sbert/bert_withoutIDF.csv
Shape of X: (2346, 768), Shape of y: 2346
Unique labels in y: ['A-J' 'BBC' 'J-P' 'NY-T']

Training ANN Topology 1...
Epoch 1/15
52/52 [==============================] - 1s 7ms/step - loss: 1.3259 - accuracy: 0.2960 - val_loss: 1.2389 - val_accuracy: 0.3949
Epoch 2/15
52/52 [==============================] - 0s 4ms/step - loss: 1.1487 - accuracy: 0.5140 - val_loss: 1.0662 - val_accuracy: 0.5994
Epoch 3/15
52/52 [==============================] - 0s 4ms/step - loss: 0.9504 - accuracy: 0.7558 - val_loss: 0.8368 - val_accuracy: 0.8324
Epoch 4/15
52/52 [==============================] - 0s 4ms/step - loss: 0.7399 - accuracy: 0.8490 - val_loss: 0.6462 - val_accuracy: 0.8722
Epoch 5/15
52/52 [==============================] - 0s 4ms/step - loss: 0.5350 - accuracy: 0.8770 - val_loss: 0.4146 - val_accuracy: 0.9006
Epoch 6/15
52/52 [==============================] - 0s 3ms/step - loss: 0.3286 - accuracy: 0.9007 - val_loss: 0.2434 - val_accuracy: 0.9205
Epoch 7/15
52/52 [==============================] - 0s 4ms/step - loss: 0.2028 - accuracy: 0.9488 - val_loss: 0.1678 - val_accuracy: 0.9574
Epoch 8/15
52/52 [==============================] - 0s 4ms/step - loss: 0.1350 - accuracy: 0.9708 - val_loss: 0.1293 - val_accuracy: 0.9744
Epoch 9/15
52/52 [==============================] - 0s 4ms/step - loss: 0.1006 - accuracy: 0.9811 - val_loss: 0.1178 - val_accuracy: 0.9659
Epoch 10/15
52/52 [==============================] - 0s 4ms/step - loss: 0.0821 - accuracy: 0.9854 - val_loss: 0.0992 - val_accuracy: 0.9773
Epoch 11/15
52/52 [==============================] - 0s 4ms/step - loss: 0.0722 - accuracy: 0.9884 - val_loss: 0.0900 - val_accuracy: 0.9801
Epoch 12/15
52/52 [==============================] - 0s 4ms/step - loss: 0.0607 - accuracy: 0.9872 - val_loss: 0.0885 - val_accuracy: 0.9716
Epoch 13/15
52/52 [==============================] - 0s 4ms/step - loss: 0.0514 - accuracy: 0.9933 - val_loss: 0.0781 - val_accuracy: 0.9830
Epoch 14/15
52/52 [==============================] - 0s 4ms/step - loss: 0.0486 - accuracy: 0.9915 - val_loss: 0.0751 - val_accuracy: 0.9858
Epoch 15/15
52/52 [==============================] - 0s 4ms/step - loss: 0.0430 - accuracy: 0.9939 - val_loss: 0.0738 - val_accuracy: 0.9858

Training ANN Topology 2...
Epoch 1/15
52/52 [==============================] - 2s 9ms/step - loss: 1.1526 - accuracy: 0.5116 - val_loss: 0.9505 - val_accuracy: 0.6847
Epoch 2/15
52/52 [==============================] - 0s 3ms/step - loss: 0.8537 - accuracy: 0.7089 - val_loss: 0.7616 - val_accuracy: 0.7102
Epoch 3/15
52/52 [==============================] - 0s 3ms/step - loss: 0.6796 - accuracy: 0.7570 - val_loss: 0.5838 - val_accuracy: 0.8239
Epoch 4/15
52/52 [==============================] - 0s 4ms/step - loss: 0.4662 - accuracy: 0.9044 - val_loss: 0.3381 - val_accuracy: 0.9545
Epoch 5/15
52/52 [==============================] - 0s 3ms/step - loss: 0.2413 - accuracy: 0.9683 - val_loss: 0.1957 - val_accuracy: 0.9830
Epoch 6/15
52/52 [==============================] - 0s 4ms/step - loss: 0.1373 - accuracy: 0.9842 - val_loss: 0.1341 - val_accuracy: 0.9631
Epoch 7/15
52/52 [==============================] - 0s 3ms/step - loss: 0.0947 - accuracy: 0.9854 - val_loss: 0.1065 - val_accuracy: 0.9688
Epoch 8/15
52/52 [==============================] - 0s 3ms/step - loss: 0.0756 - accuracy: 0.9866 - val_loss: 0.1008 - val_accuracy: 0.9773
Epoch 9/15
52/52 [==============================] - 0s 4ms/step - loss: 0.0657 - accuracy: 0.9872 - val_loss: 0.0843 - val_accuracy: 0.9801
Epoch 10/15
52/52 [==============================] - 0s 4ms/step - loss: 0.0554 - accuracy: 0.9903 - val_loss: 0.0798 - val_accuracy: 0.9830
Epoch 11/15
52/52 [==============================] - 0s 4ms/step - loss: 0.0459 - accuracy: 0.9933 - val_loss: 0.0797 - val_accuracy: 0.9830
Epoch 12/15
52/52 [==============================] - 0s 4ms/step - loss: 0.0418 - accuracy: 0.9921 - val_loss: 0.0779 - val_accuracy: 0.9801
Epoch 13/15
52/52 [==============================] - 0s 3ms/step - loss: 0.0387 - accuracy: 0.9933 - val_loss: 0.0775 - val_accuracy: 0.9744
Epoch 14/15
52/52 [==============================] - 0s 3ms/step - loss: 0.0301 - accuracy: 0.9963 - val_loss: 0.0755 - val_accuracy: 0.9773
Epoch 15/15
52/52 [==============================] - 0s 4ms/step - loss: 0.0268 - accuracy: 0.9963 - val_loss: 0.0726 - val_accuracy: 0.9773

Training Naive Bayes for bert_withoutIDF
Transforming X to non-negative values for Naive Bayes.
Naive Bayes Average Accuracy: 0.8453

Training Logistic Regression for bert_withoutIDF
Logistic Regression Average Accuracy: 0.9791

Training SVM for bert_withoutIDF
SVM Average Accuracy: 0.9774

Training Random Forest for bert_withoutIDF
Random Forest Average Accuracy: 0.9668
Results for bert_withoutIDF: {'Naive Bayes': 0.8452736861247498, 'Logistic Regression': 0.9791162029459901, 'SVM': 0.9774122567739589, 'Random Forest': 0.9667521367521367}

Processing file: sbert_vectors
Data loaded from C:/Users/danie/Desktop/IR/Information_retrieval/exe2/IR-files/bert-sbert/sbert_vectors.csv
Shape of X: (2346, 384), Shape of y: 2346
Unique labels in y: ['A-J' 'BBC' 'J-P' 'NY-T']

Training ANN Topology 1...
Epoch 1/15
52/52 [==============================] - 1s 8ms/step - loss: 1.3808 - accuracy: 0.3666 - val_loss: 1.3689 - val_accuracy: 0.3977
Epoch 2/15
52/52 [==============================] - 0s 4ms/step - loss: 1.3182 - accuracy: 0.3788 - val_loss: 1.2300 - val_accuracy: 0.4091
Epoch 3/15
52/52 [==============================] - 0s 4ms/step - loss: 1.1635 - accuracy: 0.5280 - val_loss: 1.0642 - val_accuracy: 0.6222
Epoch 4/15
52/52 [==============================] - 0s 4ms/step - loss: 1.0268 - accuracy: 0.5938 - val_loss: 0.9418 - val_accuracy: 0.6477
Epoch 5/15
52/52 [==============================] - 0s 4ms/step - loss: 0.9242 - accuracy: 0.6273 - val_loss: 0.8570 - val_accuracy: 0.6477
Epoch 6/15
52/52 [==============================] - 0s 4ms/step - loss: 0.8560 - accuracy: 0.6346 - val_loss: 0.8022 - val_accuracy: 0.6506
Epoch 7/15
52/52 [==============================] - 0s 4ms/step - loss: 0.8104 - accuracy: 0.6395 - val_loss: 0.7706 - val_accuracy: 0.6477
Epoch 8/15
52/52 [==============================] - 0s 4ms/step - loss: 0.7774 - accuracy: 0.6413 - val_loss: 0.7447 - val_accuracy: 0.6506
Epoch 9/15
52/52 [==============================] - 0s 4ms/step - loss: 0.7518 - accuracy: 0.6449 - val_loss: 0.7280 - val_accuracy: 0.6506
Epoch 10/15
52/52 [==============================] - 0s 3ms/step - loss: 0.7300 - accuracy: 0.6480 - val_loss: 0.7133 - val_accuracy: 0.6506
Epoch 11/15
52/52 [==============================] - 0s 3ms/step - loss: 0.7131 - accuracy: 0.6486 - val_loss: 0.7059 - val_accuracy: 0.6506
Epoch 12/15
52/52 [==============================] - 0s 4ms/step - loss: 0.6957 - accuracy: 0.6699 - val_loss: 0.6935 - val_accuracy: 0.6761
Epoch 13/15
52/52 [==============================] - 0s 3ms/step - loss: 0.6821 - accuracy: 0.7125 - val_loss: 0.6849 - val_accuracy: 0.7273
Epoch 14/15
52/52 [==============================] - 0s 4ms/step - loss: 0.6703 - accuracy: 0.7235 - val_loss: 0.6819 - val_accuracy: 0.7074
Epoch 15/15
52/52 [==============================] - 0s 4ms/step - loss: 0.6588 - accuracy: 0.7314 - val_loss: 0.6737 - val_accuracy: 0.7330

Training ANN Topology 2...
Epoch 1/15
52/52 [==============================] - 2s 9ms/step - loss: 1.3691 - accuracy: 0.4068 - val_loss: 1.3290 - val_accuracy: 0.1932
Epoch 2/15
52/52 [==============================] - 0s 3ms/step - loss: 1.2632 - accuracy: 0.2631 - val_loss: 1.1716 - val_accuracy: 0.3352
Epoch 3/15
52/52 [==============================] - 0s 3ms/step - loss: 1.1331 - accuracy: 0.4294 - val_loss: 1.0542 - val_accuracy: 0.4943
Epoch 4/15
52/52 [==============================] - 0s 3ms/step - loss: 1.0268 - accuracy: 0.5725 - val_loss: 0.9580 - val_accuracy: 0.6392
Epoch 5/15
52/52 [==============================] - 0s 4ms/step - loss: 0.9398 - accuracy: 0.6285 - val_loss: 0.8888 - val_accuracy: 0.6477
Epoch 6/15
52/52 [==============================] - 0s 3ms/step - loss: 0.8775 - accuracy: 0.6370 - val_loss: 0.8356 - val_accuracy: 0.6619
Epoch 7/15
52/52 [==============================] - 0s 4ms/step - loss: 0.8244 - accuracy: 0.6565 - val_loss: 0.7916 - val_accuracy: 0.6619
Epoch 8/15
52/52 [==============================] - 0s 4ms/step - loss: 0.7815 - accuracy: 0.6620 - val_loss: 0.7597 - val_accuracy: 0.6705
Epoch 9/15
52/52 [==============================] - 0s 4ms/step - loss: 0.7494 - accuracy: 0.6766 - val_loss: 0.7299 - val_accuracy: 0.6847
Epoch 10/15
52/52 [==============================] - 0s 4ms/step - loss: 0.7242 - accuracy: 0.6876 - val_loss: 0.7141 - val_accuracy: 0.6875
Epoch 11/15
52/52 [==============================] - 0s 4ms/step - loss: 0.7054 - accuracy: 0.6979 - val_loss: 0.7037 - val_accuracy: 0.6960
Epoch 12/15
52/52 [==============================] - 0s 4ms/step - loss: 0.6890 - accuracy: 0.7095 - val_loss: 0.6970 - val_accuracy: 0.7045
Epoch 13/15
52/52 [==============================] - 0s 3ms/step - loss: 0.6772 - accuracy: 0.7083 - val_loss: 0.6882 - val_accuracy: 0.7159
Epoch 14/15
52/52 [==============================] - 0s 3ms/step - loss: 0.6640 - accuracy: 0.7314 - val_loss: 0.6822 - val_accuracy: 0.7244
Epoch 15/15
52/52 [==============================] - 0s 3ms/step - loss: 0.6522 - accuracy: 0.7326 - val_loss: 0.6833 - val_accuracy: 0.7159

Training Naive Bayes for sbert_vectors
Transforming X to non-negative values for Naive Bayes.
Naive Bayes Average Accuracy: 0.6078

Training Logistic Regression for sbert_vectors
Logistic Regression Average Accuracy: 0.7118

Training SVM for sbert_vectors
Logistic Regression Average Accuracy: 0.7118

Training SVM for sbert_vectors

Training SVM for sbert_vectors
SVM Average Accuracy: 0.6270
Training SVM for sbert_vectors
SVM Average Accuracy: 0.6270
SVM Average Accuracy: 0.6270

Training Random Forest for sbert_vectors

Training Random Forest for sbert_vectors
Random Forest Average Accuracy: 0.8836
Results for sbert_vectors: {'Naive Bayes': 0.6078414257137661, 'Logistic Regression': 0.7118385160938352, 'SVM': 0.62Training Random Forest for sbert_vectors
Random Forest Average Accuracy: 0.8836
Results for sbert_vectors: {'Naive Bayes': 0.6078414257137661, 'Logistic Regression': 0.7118385160938352, 'SVM': 0.62Random Forest Average Accuracy: 0.8836
Results for sbert_vectors: {'Naive Bayes': 0.6078414257137661, 'Logistic Regression': 0.7118385160938352, 'SVM': 0.62Results for sbert_vectors: {'Naive Bayes': 0.6078414257137661, 'Logistic Regression': 0.7118385160938352, 'SVM': 0.6270230951082014, 'Random Forest': 0.8836461174759048}
All tasks completed successfully!

C:\Users\danie\Desktop\IR\Information_retrieval\exe2>

C:\Users\danie\Desktop\IR\Information_retrieval\exe2>
C:\Users\danie\Desktop\IR\Information_retrieval\exe2> c: && cd c:\Users\danie\Desktop\IR\Information_retrieval\exe2 && cmd /C "c:\Users\danie\AppData\Local\Programs\Python\Python311\python.exe c:\Users\danie\.vscode\extensions\ms-python.debugpy-2024.14.0-win32-x64\bundled\libs\debugpy\adapter/../..\debugpy\launcher 63213 -- C:\Users\danie\Desktop\IR\Information_retrieval\exe2\bert_sbert_classification.py "

Processing file: bert_withIDF
Data loaded from C:/Users/danie/Desktop/IR/Information_retrieval/exe2/IR-files/bert-sbert/bert_withIDF.csv
Shape of X: (2346, 768), Shape of y: 2346     
Unique labels in y: ['A-J' 'BBC' 'J-P' 'NY-T']

Training ANN Topology 1...
Epoch 1/15
52/52 [==============================] - 1s 8ms/step - loss: 1.2862 - accuracy: 0.2887 - val_loss: 1.1402 - val_accuracy: 0.4091
Epoch 2/15
52/52 [==============================] - 0s 4ms/step - loss: 0.9825 - accuracy: 0.5609 - val_loss: 0.6987 - val_accuracy: 0.8381
Epoch 3/15
52/52 [==============================] - 0s 4ms/step - loss: 0.5770 - accuracy: 0.8605 - val_loss: 0.4338 - val_accuracy: 0.8977
Epoch 4/15
52/52 [==============================] - 0s 4ms/step - loss: 0.3821 - accuracy: 0.8855 - val_loss: 0.3340 - val_accuracy: 0.9062
Epoch 5/15
52/52 [==============================] - 0s 3ms/step - loss: 0.2999 - accuracy: 0.9007 - val_loss: 0.3021 - val_accuracy: 0.9062
Epoch 6/15
52/52 [==============================] - 0s 4ms/step - loss: 0.2538 - accuracy: 0.9184 - val_loss: 0.2267 - val_accuracy: 0.9261
Epoch 7/15
52/52 [==============================] - 0s 3ms/step - loss: 0.2044 - accuracy: 0.9361 - val_loss: 0.2018 - val_accuracy: 0.9347
Epoch 8/15
52/52 [==============================] - 0s 3ms/step - loss: 0.1712 - accuracy: 0.9440 - val_loss: 0.1803 - val_accuracy: 0.9460
Epoch 9/15
52/52 [==============================] - 0s 3ms/step - loss: 0.1532 - accuracy: 0.9580 - val_loss: 0.1697 - val_accuracy: 0.9460
Epoch 10/15
52/52 [==============================] - 0s 4ms/step - loss: 0.1306 - accuracy: 0.9659 - val_loss: 0.1574 - val_accuracy: 0.9517
Epoch 11/15
52/52 [==============================] - 0s 4ms/step - loss: 0.1121 - accuracy: 0.9756 - val_loss: 0.1458 - val_accuracy: 0.9602
Epoch 12/15
52/52 [==============================] - 0s 4ms/step - loss: 0.0989 - accuracy: 0.9781 - val_loss: 0.1382 - val_accuracy: 0.9631
Epoch 13/15
52/52 [==============================] - 0s 4ms/step - loss: 0.0958 - accuracy: 0.9750 - val_loss: 0.1299 - val_accuracy: 0.9631
Epoch 14/15
52/52 [==============================] - 0s 4ms/step - loss: 0.0868 - accuracy: 0.9805 - val_loss: 0.1282 - val_accuracy: 0.9659
Epoch 15/15
52/52 [==============================] - 0s 4ms/step - loss: 0.0781 - accuracy: 0.9787 - val_loss: 0.1216 - val_accuracy: 0.9688

Training ANN Topology 2...
Epoch 1/15
52/52 [==============================] - 2s 7ms/step - loss: 1.0044 - accuracy: 0.5853 - val_loss: 0.7046 - val_accuracy: 0.8097
Epoch 2/15
52/52 [==============================] - 0s 4ms/step - loss: 0.5397 - accuracy: 0.8788 - val_loss: 0.3892 - val_accuracy: 0.9176
Epoch 3/15
52/52 [==============================] - 0s 3ms/step - loss: 0.2959 - accuracy: 0.9403 - val_loss: 0.2631 - val_accuracy: 0.9602
Epoch 4/15
52/52 [==============================] - 0s 4ms/step - loss: 0.1959 - accuracy: 0.9549 - val_loss: 0.2058 - val_accuracy: 0.9460
Epoch 5/15
52/52 [==============================] - 0s 4ms/step - loss: 0.1422 - accuracy: 0.9677 - val_loss: 0.1666 - val_accuracy: 0.9716
Epoch 6/15
52/52 [==============================] - 0s 4ms/step - loss: 0.1084 - accuracy: 0.9744 - val_loss: 0.1610 - val_accuracy: 0.9574
Epoch 7/15
52/52 [==============================] - 0s 3ms/step - loss: 0.0873 - accuracy: 0.9823 - val_loss: 0.1655 - val_accuracy: 0.9716
Epoch 8/15
52/52 [==============================] - 0s 3ms/step - loss: 0.0794 - accuracy: 0.9836 - val_loss: 0.1677 - val_accuracy: 0.9602
Epoch 9/15
52/52 [==============================] - 0s 4ms/step - loss: 0.0630 - accuracy: 0.9878 - val_loss: 0.1366 - val_accuracy: 0.9716
Epoch 10/15
52/52 [==============================] - 0s 4ms/step - loss: 0.0562 - accuracy: 0.9866 - val_loss: 0.1263 - val_accuracy: 0.9773
Epoch 11/15
52/52 [==============================] - 0s 4ms/step - loss: 0.0432 - accuracy: 0.9903 - val_loss: 0.1229 - val_accuracy: 0.9744
Epoch 12/15
52/52 [==============================] - 0s 4ms/step - loss: 0.0356 - accuracy: 0.9933 - val_loss: 0.1264 - val_accuracy: 0.9773
Epoch 13/15
52/52 [==============================] - 0s 4ms/step - loss: 0.0345 - accuracy: 0.9939 - val_loss: 0.1207 - val_accuracy: 0.9716
Epoch 14/15
52/52 [==============================] - 0s 3ms/step - loss: 0.0259 - accuracy: 0.9945 - val_loss: 0.1250 - val_accuracy: 0.9716
Epoch 15/15
52/52 [==============================] - 0s 3ms/step - loss: 0.0237 - accuracy: 0.9970 - val_loss: 0.1285 - val_accuracy: 0.9744

Training Naive Bayes for bert_withIDF
Transforming X to non-negative values for Naive Bayes.
Naive Bayes Average Accuracy: 0.8551

Training Logistic Regression for bert_withIDF
Logistic Regression Average Accuracy: 0.9736

Training SVM for bert_withIDF
SVM Average Accuracy: 0.9736

Training Random Forest for bert_withIDF
Random Forest Average Accuracy: 0.9544
Results for bert_withIDF: {'Naive Bayes': 0.8550772867794144, 'Logistic Regression': 0.9735715584651754, 'SVM': 0.973577014002546, 'Random Forest': 0.9543844335333697}

Processing file: bert_withoutIDF
Data loaded from C:/Users/danie/Desktop/IR/Information_retrieval/exe2/IR-files/bert-sbert/bert_withoutIDF.csv
Shape of X: (2346, 768), Shape of y: 2346
Unique labels in y: ['A-J' 'BBC' 'J-P' 'NY-T']

Training ANN Topology 1...
Epoch 1/15
52/52 [==============================] - 1s 7ms/step - loss: 1.3379 - accuracy: 0.3136 - val_loss: 1.2876 - val_accuracy: 0.4489
Epoch 2/15
52/52 [==============================] - 0s 4ms/step - loss: 1.2400 - accuracy: 0.4519 - val_loss: 1.1838 - val_accuracy: 0.4688
Epoch 3/15
52/52 [==============================] - 0s 4ms/step - loss: 1.1348 - accuracy: 0.5676 - val_loss: 1.0754 - val_accuracy: 0.6818
Epoch 4/15
52/52 [==============================] - 0s 4ms/step - loss: 0.9773 - accuracy: 0.7247 - val_loss: 0.8579 - val_accuracy: 0.7670
Epoch 5/15
52/52 [==============================] - 0s 3ms/step - loss: 0.6703 - accuracy: 0.8191 - val_loss: 0.4652 - val_accuracy: 0.9148
Epoch 6/15
52/52 [==============================] - 0s 4ms/step - loss: 0.3227 - accuracy: 0.9458 - val_loss: 0.2397 - val_accuracy: 0.9517
Epoch 7/15
52/52 [==============================] - 0s 3ms/step - loss: 0.2075 - accuracy: 0.9531 - val_loss: 0.1851 - val_accuracy: 0.9545
Epoch 8/15
52/52 [==============================] - 0s 3ms/step - loss: 0.1539 - accuracy: 0.9671 - val_loss: 0.2007 - val_accuracy: 0.9460
Epoch 9/15
52/52 [==============================] - 0s 4ms/step - loss: 0.1243 - accuracy: 0.9738 - val_loss: 0.1320 - val_accuracy: 0.9631
Epoch 10/15
52/52 [==============================] - 0s 4ms/step - loss: 0.1009 - accuracy: 0.9762 - val_loss: 0.1174 - val_accuracy: 0.9659
Epoch 11/15
52/52 [==============================] - 0s 4ms/step - loss: 0.0885 - accuracy: 0.9829 - val_loss: 0.1145 - val_accuracy: 0.9716
Epoch 12/15
52/52 [==============================] - 0s 3ms/step - loss: 0.0708 - accuracy: 0.9896 - val_loss: 0.1172 - val_accuracy: 0.9688
Epoch 13/15
52/52 [==============================] - 0s 4ms/step - loss: 0.0620 - accuracy: 0.9884 - val_loss: 0.1023 - val_accuracy: 0.9716
Epoch 14/15
52/52 [==============================] - 0s 3ms/step - loss: 0.0563 - accuracy: 0.9903 - val_loss: 0.1043 - val_accuracy: 0.9744
Epoch 15/15
52/52 [==============================] - 0s 5ms/step - loss: 0.0493 - accuracy: 0.9933 - val_loss: 0.0962 - val_accuracy: 0.9773

Training ANN Topology 2...
Epoch 1/15
52/52 [==============================] - 2s 7ms/step - loss: 1.0991 - accuracy: 0.4945 - val_loss: 0.8091 - val_accuracy: 0.6619
Epoch 2/15
52/52 [==============================] - 0s 3ms/step - loss: 0.6678 - accuracy: 0.7004 - val_loss: 0.5256 - val_accuracy: 0.8011
Epoch 3/15
52/52 [==============================] - 0s 4ms/step - loss: 0.4758 - accuracy: 0.8234 - val_loss: 0.4198 - val_accuracy: 0.8636
Epoch 4/15
52/52 [==============================] - 0s 3ms/step - loss: 0.3685 - accuracy: 0.8959 - val_loss: 0.3310 - val_accuracy: 0.8977
Epoch 5/15
52/52 [==============================] - 0s 3ms/step - loss: 0.2877 - accuracy: 0.9281 - val_loss: 0.2670 - val_accuracy: 0.9375
Epoch 6/15
52/52 [==============================] - 0s 3ms/step - loss: 0.2204 - accuracy: 0.9482 - val_loss: 0.2217 - val_accuracy: 0.9545
Epoch 7/15
52/52 [==============================] - 0s 4ms/step - loss: 0.1721 - accuracy: 0.9702 - val_loss: 0.1903 - val_accuracy: 0.9631
Epoch 8/15
52/52 [==============================] - 0s 3ms/step - loss: 0.1317 - accuracy: 0.9744 - val_loss: 0.1771 - val_accuracy: 0.9602
Epoch 9/15
52/52 [==============================] - 0s 3ms/step - loss: 0.1086 - accuracy: 0.9805 - val_loss: 0.1586 - val_accuracy: 0.9688
Epoch 10/15
52/52 [==============================] - 0s 3ms/step - loss: 0.0890 - accuracy: 0.9866 - val_loss: 0.1579 - val_accuracy: 0.9659
Epoch 11/15
52/52 [==============================] - 0s 3ms/step - loss: 0.0713 - accuracy: 0.9890 - val_loss: 0.1432 - val_accuracy: 0.9716
Epoch 12/15
52/52 [==============================] - 0s 4ms/step - loss: 0.0607 - accuracy: 0.9896 - val_loss: 0.1398 - val_accuracy: 0.9716
Epoch 13/15
52/52 [==============================] - 0s 4ms/step - loss: 0.0506 - accuracy: 0.9927 - val_loss: 0.1890 - val_accuracy: 0.9602
Epoch 14/15
52/52 [==============================] - 0s 4ms/step - loss: 0.0474 - accuracy: 0.9927 - val_loss: 0.1326 - val_accuracy: 0.9773
Epoch 15/15
52/52 [==============================] - 0s 3ms/step - loss: 0.0407 - accuracy: 0.9945 - val_loss: 0.1358 - val_accuracy: 0.9716

Training Naive Bayes for bert_withoutIDF
Transforming X to non-negative values for Naive Bayes.
Naive Bayes Average Accuracy: 0.8453

Training Logistic Regression for bert_withoutIDF
Logistic Regression Average Accuracy: 0.9791

Training SVM for bert_withoutIDF
SVM Average Accuracy: 0.9774

Training Random Forest for bert_withoutIDF
Random Forest Average Accuracy: 0.9638
Results for bert_withoutIDF: {'Naive Bayes': 0.8452736861247498, 'Logistic Regression': 0.9791162029459901, 'SVM': 0.9774122567739589, 'Random Forest': 0.9637697763229678}

Processing file: sbert_vectors
Data loaded from C:/Users/danie/Desktop/IR/Information_retrieval/exe2/IR-files/bert-sbert/sbert_vectors.csv
Shape of X: (2346, 384), Shape of y: 2346
Unique labels in y: ['A-J' 'BBC' 'J-P' 'NY-T']

Training ANN Topology 1...
Epoch 1/15
52/52 [==============================] - 1s 8ms/step - loss: 1.3716 - accuracy: 0.4080 - val_loss: 1.3419 - val_accuracy: 0.4148
Epoch 2/15
52/52 [==============================] - 0s 3ms/step - loss: 1.2938 - accuracy: 0.4056 - val_loss: 1.2120 - val_accuracy: 0.4176
Epoch 3/15
52/52 [==============================] - 0s 3ms/step - loss: 1.1563 - accuracy: 0.3989 - val_loss: 1.0736 - val_accuracy: 0.4148
Epoch 4/15
52/52 [==============================] - 0s 3ms/step - loss: 1.0529 - accuracy: 0.4019 - val_loss: 0.9934 - val_accuracy: 0.4205
Epoch 5/15
52/52 [==============================] - 0s 4ms/step - loss: 0.9826 - accuracy: 0.5055 - val_loss: 0.9238 - val_accuracy: 0.6392
Epoch 6/15
52/52 [==============================] - 0s 4ms/step - loss: 0.9104 - accuracy: 0.6212 - val_loss: 0.8561 - val_accuracy: 0.6420
Epoch 7/15
52/52 [==============================] - 0s 4ms/step - loss: 0.8489 - accuracy: 0.6322 - val_loss: 0.8026 - val_accuracy: 0.6506
Epoch 8/15
52/52 [==============================] - 0s 5ms/step - loss: 0.7986 - accuracy: 0.6370 - val_loss: 0.7625 - val_accuracy: 0.6477
Epoch 9/15
52/52 [==============================] - 0s 4ms/step - loss: 0.7585 - accuracy: 0.6413 - val_loss: 0.7314 - val_accuracy: 0.6506
Epoch 10/15
52/52 [==============================] - 0s 4ms/step - loss: 0.7256 - accuracy: 0.6468 - val_loss: 0.7083 - val_accuracy: 0.6506
Epoch 11/15
52/52 [==============================] - 0s 5ms/step - loss: 0.6998 - accuracy: 0.6900 - val_loss: 0.6930 - val_accuracy: 0.7102
Epoch 12/15
52/52 [==============================] - 0s 4ms/step - loss: 0.6792 - accuracy: 0.7253 - val_loss: 0.6804 - val_accuracy: 0.7216
Epoch 13/15
52/52 [==============================] - 0s 5ms/step - loss: 0.6635 - accuracy: 0.7375 - val_loss: 0.6757 - val_accuracy: 0.7131
Epoch 14/15
52/52 [==============================] - 0s 5ms/step - loss: 0.6490 - accuracy: 0.7418 - val_loss: 0.6658 - val_accuracy: 0.7358
Epoch 15/15
52/52 [==============================] - 0s 4ms/step - loss: 0.6370 - accuracy: 0.7430 - val_loss: 0.6656 - val_accuracy: 0.7216

Training ANN Topology 2...
Epoch 1/15
52/52 [==============================] - 2s 8ms/step - loss: 1.3789 - accuracy: 0.2637 - val_loss: 1.3577 - val_accuracy: 0.2727
Epoch 2/15
52/52 [==============================] - 0s 3ms/step - loss: 1.3095 - accuracy: 0.2393 - val_loss: 1.2114 - val_accuracy: 0.2699
Epoch 3/15
52/52 [==============================] - 0s 3ms/step - loss: 1.1707 - accuracy: 0.3849 - val_loss: 1.0880 - val_accuracy: 0.5369
Epoch 4/15
52/52 [==============================] - 0s 3ms/step - loss: 1.0580 - accuracy: 0.5865 - val_loss: 0.9700 - val_accuracy: 0.6420
Epoch 5/15
52/52 [==============================] - 0s 4ms/step - loss: 0.9405 - accuracy: 0.6230 - val_loss: 0.8587 - val_accuracy: 0.6420
Epoch 6/15
52/52 [==============================] - 0s 4ms/step - loss: 0.8423 - accuracy: 0.6401 - val_loss: 0.7825 - val_accuracy: 0.6676
Epoch 7/15
52/52 [==============================] - 0s 4ms/step - loss: 0.7750 - accuracy: 0.6626 - val_loss: 0.7360 - val_accuracy: 0.6989
Epoch 8/15
52/52 [==============================] - 0s 3ms/step - loss: 0.7310 - accuracy: 0.6882 - val_loss: 0.7102 - val_accuracy: 0.6903
Epoch 9/15
52/52 [==============================] - 0s 3ms/step - loss: 0.7035 - accuracy: 0.7028 - val_loss: 0.6950 - val_accuracy: 0.7131
Epoch 10/15
52/52 [==============================] - 0s 3ms/step - loss: 0.6865 - accuracy: 0.7052 - val_loss: 0.6903 - val_accuracy: 0.7188
Epoch 11/15
52/52 [==============================] - 0s 4ms/step - loss: 0.6724 - accuracy: 0.7162 - val_loss: 0.6801 - val_accuracy: 0.7102
Epoch 12/15
52/52 [==============================] - 0s 3ms/step - loss: 0.6583 - accuracy: 0.7174 - val_loss: 0.6769 - val_accuracy: 0.7188
Epoch 13/15
52/52 [==============================] - 0s 3ms/step - loss: 0.6478 - accuracy: 0.7284 - val_loss: 0.6731 - val_accuracy: 0.7188
Epoch 14/15
52/52 [==============================] - 0s 3ms/step - loss: 0.6357 - accuracy: 0.7363 - val_loss: 0.6682 - val_accuracy: 0.7216
Epoch 15/15
52/52 [==============================] - 0s 3ms/step - loss: 0.6267 - accuracy: 0.7381 - val_loss: 0.6697 - val_accuracy: 0.7273

Training Naive Bayes for sbert_vectors
Transforming X to non-negative values for Naive Bayes.
Naive Bayes Average Accuracy: 0.6078

Training Logistic Regression for sbert_vectors
Logistic Regression Average Accuracy: 0.7118

acy: 0.7188
Epoch 14/15
52/52 [==============================] - 0s 3ms/step - loss: 0.6357 - accuracy: 0.7363 - val_loss: 0.6682 - val_accuracy: 0.7216
Epoch 15/15
52/52 [==============================] - 0s 3ms/step - loss: 0.6267 - accuracy: 0.7381 - val_loss: 0.6697 - val_accuracy: 0.7273

Training Naive Bayes for sbert_vectors
Transforming X to non-negative values for Naive Bayes.
Naive Bayes Average Accuracy: 0.6078

Training Logistic Regression for sbert_vectors
Logistic Regression Average Accuracy: 0.7118

Training SVM for sbert_vectors
acy: 0.7188
Epoch 14/15
52/52 [==============================] - 0s 3ms/step - loss: 0.6357 - accuracy: 0.7363 - val_loss: 0.6682 - val_accuracy: 0.7216
Epoch 15/15
52/52 [==============================] - 0s 3ms/step - loss: 0.6267 - accuracy: 0.7381 - val_loss: 0.6697 - val_accuracy: 0.7273

Training Naive Bayes for sbert_vectors
Transforming X to non-negative values for Naive Bayes.
Naive Bayes Average Accuracy: 0.6078

Training Logistic Regression for sbert_vectors
Logistic Regression Average Accuracy: 0.7118

52/52 [==============================] - 0s 3ms/step - loss: 0.6357 - accuracy: 0.7363 - val_loss: 0.6682 - val_accuracy: 0.7216
Epoch 15/15
52/52 [==============================] - 0s 3ms/step - loss: 0.6267 - accuracy: 0.7381 - val_loss: 0.6697 - val_accuracy: 0.7273

Training Naive Bayes for sbert_vectors
Transforming X to non-negative values for Naive Bayes.
Naive Bayes Average Accuracy: 0.6078

Training Logistic Regression for sbert_vectors
Logistic Regression Average Accuracy: 0.7118

Epoch 15/15
52/52 [==============================] - 0s 3ms/step - loss: 0.6267 - accuracy: 0.7381 - val_loss: 0.6697 - val_accuracy: 0.7273

Training Naive Bayes for sbert_vectors
Transforming X to non-negative values for Naive Bayes.
Naive Bayes Average Accuracy: 0.6078

Training Logistic Regression for sbert_vectors
Logistic Regression Average Accuracy: 0.7118

acy: 0.7273

Training Naive Bayes for sbert_vectors
Transforming X to non-negative values for Naive Bayes.
Naive Bayes Average Accuracy: 0.6078

Training Logistic Regression for sbert_vectors
Logistic Regression Average Accuracy: 0.7118

Training Naive Bayes for sbert_vectors
Transforming X to non-negative values for Naive Bayes.
Naive Bayes Average Accuracy: 0.6078

Training Logistic Regression for sbert_vectors
Logistic Regression Average Accuracy: 0.7118

Logistic Regression Average Accuracy: 0.7118

Training SVM for sbert_vectorsד

Training SVM for sbert_vectors
Training SVM for sbert_vectors
SVM Average Accuracy: 0.6270

Training Random Forest for sbert_vectors

Training Random Forest for sbert_vectors
Training Random Forest for sbert_vectors
Random Forest Average Accuracy: 0.8853
Results for sbert_vectors: {'Naive Bayes': 0.6078414257137661, 'Logistic Regression': 0.7118385160938352, 'SVM': 0.6270230951082014, 'Random Forest': 0.8853427895981089}
All tasks completed successfully!